# myself

我叫ysj，19年毕业于西南财经大学，在校自学python编程，毕业后学习前端，进入麦杰康科技实习，由于当时后端空缺，被安排做后端工作，主要语言为nodejs，实习期满后，20年进入知道创宇做后端开发，主要语言为python和golang，工作的内容主要是负责内容安全监测系统和内容爬虫系统的设计、开发、测试、部署和维护整个流程。



不同地区的合作问题，成都只负责数据采集？存储、分析？

# projects

1. 爬虫系统

   * 21年初和旧版的内容监测系统一起开发，一开始由我领导独立开发，后来他离职了，项目交到我手里，此时的爬虫系统有很多问题，根本没办法维护。

   * 由于当时面临三大运营商业务招标的需求，急需救活项目，然后我决定重写爬虫系统，老板<总经理>在我旁边看着，前前后后熬了好几个通宵，最后成功完成了重构。

   * 爬虫系统主要设计了五个模块，分别如下：

     * `schedular:` 调度器。

       1). 负责接收rabbitmq的域名消息，然后根据配置的域名爬取并发数，分别下发具体的域名爬取任务。

       2). 超时控制，域名爬取超时，对应的域名爬取任务终止。

       3). 域名爬取注册。通过rpc将域名当前的爬取情况，如爬取数、深度等信息通过流的形式实时发送到监控服务。这里我写了一个类似htop的终端监控程序。

     * `collector:` 收集器。

       1). 具体的域名爬取循环。

       2). 负责url过滤、去重，域名白名单过滤。

       3). 请求首页组装，跳转试探

       4). 深度、数量控制

       5). 请求队列维护

     * `downloader`: 下载器。

       1). 负责页面内容的获取

       2). 处理页面跳转和编码问题

     * `analyzer`: 分析器。

       1). 主要负责提取页面中的子链接，包含标签链接、文本中疑似链接、域名、ip等

       2). 将子链接封装为请求对象，放入请求队列

     * `proccessor`: 处理器。

       1). 负责对爬取的页面内容做业务处理，包含请求错误处理、请求正常响应的处理

       2). 对页面内容进行分词、查找匹配违规内容(词语匹配->违规ip匹配->自定义匹配)

       3). 数据存库

   * 爬虫系统主要有以下重难点:

     * 特殊的业务需求很多，无法快速应用爬虫框架实现，考虑到后期需求面的扩大，只能从http基本的请求开始写起；中间重构的时候其实使用过golang的colly爬虫框架来写，但尝试失败了，有些业务逻辑实现不了。

     * 深度控制

     * 最大爬取量控制

     * 并发控制，由于并发数过大，有些客户的网站都崩掉了

     * 内外链判断，有些链接从技术上来说属于内链，比如两个url的域名不同，但是指向的ip是相同的，严格来说这种情况应该定位为内链，但从客户的角度来说客户无法理解，他们觉得是外链

     * 请求跳转问题

     * **动态页面问题**

     * **请求链溯源问题**<colly无法实现的最大阻碍>，我的实现—封装请求对象为树结构，层层往上拼接url

     * **编码问题**。页面中提取、响应头(encoding)中提取、使用库进行编码探测、最后保底默认为utf8

     * **完成时机问题**，即什么时候爬取完成。前领导写的那版爬虫就是在这里问题最大，他通过间断轮询数据库，数据量不再增长即视为完成，这显然不可行(时间问题、程序暂停问题)，导致经常爬取不完全，而重爬。

       利用了解析的速度>处理的速度，通过两个计数器，做原子计数即可解决——已爬取数+有效数。 (过滤后放入有效请求队列，不能放入后再过滤，否则计数就乱了，无法相等退出)

     * 其他，如资源有限的问题，服务器、带宽不足，给我们开发带来了不少压力

2. 内容安全监测系统(旧)

   * 刚入职的时候，从离职前辈的手里接手的项目。采用的是`django+celery+mysql8`实现。

   * 后来，和爬虫系统同一时期做并行开发。

   * 系统的主要功能是提供管理后台、客户端界面需要接口，任务下发功能、以及流程控制。

   * 这个项目主要面临如下困难：

     1). 基于旧项目进行开发，旧项目原有的功能代码紊乱、文档缺失、bug很多

     2). 需求迭代后，项目里原有的功能基本成了空壳，没有用。(我当初开发时请求重开项目被领导否了)

     3). 基于上述原因，导致后续的功能只能在原有的基础上不断填充。bug越来越多，随着需求的增加，扩展越来越难

     4). 设计上的不足：

     * 索引设计存在问题。整个项目基本全是单字段索引、不管字段值的基数如何都在建索引。索引字段过多。
     * 字段设计存在问题。很多状态类、枚举类字段不存数字，全是字符串。
     * 冗余字段过多。因为多人开发，需求理解不同步，一个字段可以解决的问题，建了多个。

     5). 数据库选型不谨慎

     * 因为数据量大，mysql通常在过千万数据的时候通常就应该考虑分库分表了，我们的监测任务有时候一个就能爬取1千多万数据。
     * 因为要展示数据统计，数据库经常要做count计算，mysql8不像mysql5.7版本自己维护了数据表的count，每次count计数查询非常缓慢，再加上索引、字段等设计不合理，造成整个项目查询非常慢。
     * 由于是基于已有的设计做的开发，我们只能暂时通过读写分离缓解读写压力
     * 由于精力有限， mysql维护成本过高，慢慢的变得难以维护。

     6). celery内存泄露经常导致服务器oom。

     7). 由于服务器资源有限。为了减少redis内存占用, 消息传递只传递数据库记录的id，导致每一个异步任务都在重复查询，进一步加大了数据库的压力。

   3. 内容安全云监测系统(新)

      基于上述原因，在今年年初开始计划重构，从2月底开始正式开始写。4月中旬基本完成重构。

      这个系统主要采用了golang作为开发语言，采用`go-zero`框架做微服务开发。

      数据库自建了`mongodb`分片集。

      内部服务之间通过rpc调用，没有鉴权、登录验证等，效率很高。

      暴露给前端的接口服务，采用python的fastapi框架将各个服务的请求数据进行整合、组装返回给前端。

      项目最终有如下优化:

      * 按业务拆分为功能模块，相互之间耦合性底。
      * 建立了共同的开发规范、文档齐全。
      * 过程中，我还开发了api、proto自动生成工具，数据拷贝库，大大提升了开发效率。
      * golang和fastapi，高效的语言和框架，保证了整个服务的运行效率。
      * 业务端优化，改变界面的交互逻辑，让页面展示尽量走数据库索引查询。
      * 数据库字段设计，状态类、类别类字段，统一使用数字枚举，保证字段查询的效率。
      * 数据库索引设计，根据业务需要建立适当的复合索引，拒绝在变化小的字段上建无用索引。
      * 数据库适当的做反范式设计，在查询时减少了不必要的关联。
      * 合理利用缓存。一是redis缓存，get查询缓存、需要状态判断的情景，通过设置redis计数来判断，避免去扫描数据库。二是进程间缓存，当我们需要持续更新数据库某些记录时，在应用端使用批量处理，把这一批数据计算出的最终数据更新到数据库，多次更新变为了一次更新。
      * 采用数据库监控，实现了实时统计。利用mongodb的监控功能监控数据的插入操作，每插入一条记录，计数器+1，然后将阶段性的计数结果更新到数据库统计表，从而避免了不断去做数据库的count操作。





redis

mysql

mongo

network

python

golang

# why leave？

1. 工作强度太大，付出与回报不成正比，有能力，又勤勤恳恳认真负责的工作，收入又不及同龄和应届
2. 年纪不小了，经济压力比较大，考虑现实优于理想
3. 想见识下其他业务领域的技术应用，而不是局限于当前
4. 公司要搬迁，通勤距离变远
5. 户口在天府新区，想攒天府新区的社保资格，但公司一直缴纳的是高新区的，购房资格很尴尬
6. 想找一个能够长期发力的地方去工作和沉淀